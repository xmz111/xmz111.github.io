<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <name style="font-size: 40px; font-weight: bold;">Zanyi Wang</name>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zanyi Wang</name>
              </p>
              <p>I am a MS student in Electrical and Computer Engineering (ECE) at the <a href="https://ucsd.edu/">University of California, San Diego (UCSD)</a>.
              </p>
              <p>
                Previously, I received my B.Eng. in Automation Engineering from <a href="http://en.xjtu.edu.cn/">Xi’an Jiaotong University (XJTU)</a>. I also spent a wonderful time as an exchange student at CUHK.
              </p>
              <p>
                My research interests lie in <strong>Video Understanding</strong> and <strong>Generative Modeling</strong>.
              </p>
              <p style="text-align:center">
                <a href="mailto:zaw003@ucsd.edu">Email</a> &nbsp/&nbsp
                <a href="https://github.com/xmz111">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <li style="margin: 5px;"> <strong>[2026-01]</strong> One paper accepted to <strong>ICLR 2026</strong>!</li>
                <li style="margin: 5px;"> <strong>[2025-08]</strong> One paper accepted to <strong>ACM MM 2025</strong>!</li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
              <p>
                (* denotes equal contribution)
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr onmouseout="iclr26_stop()" onmouseover="iclr26_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/iclr26.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/YOUR_PAPER_LINK">
                <papertitle>Deforming Videos to Masks: Flow Matching for Referring Video Segmentation</papertitle>
              </a>
              <br>
              <strong>Zanyi Wang</strong>, Dengyang Jiang, Liuzhuozheng Li, Sizhe Dang, Chengzu Li, Harry Yang, Guang Dai, Mengmeng Wang, Jingdong Wang
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2026
              <br>
              <a href="https://github.com/YOUR_REPO">project page</a> /
              <a href="https://arxiv.org/abs/YOUR_PAPER">arXiv</a>
              <p></p>
              <p>
                Reformulated RVOS as learning a continuous, text-conditioned flow that deforms a video's content into its target mask.
              </p>
            </td>
          </tr>

          <tr onmouseout="acmmm25_stop()" onmouseover="acmmm25_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/acmmm25.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/YOUR_PAPER_LINK">
                <papertitle>TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP</papertitle>
              </a>
              <br>
              Fan Li*, <strong>Zanyi Wang*</strong>, Zeyi Huang, Guang Dai, Jingdong Wang, Mengmeng Wang
              <br>
              <em>ACM International Conference on Multimedia (ACM MM)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/YOUR_PAPER">arXiv</a>
              <p></p>
              <p>
                Developed a unified framework leveraging CLIP’s ViT encoder for efficient tri-modal 3D visual grounding.
              </p>
            </td>
          </tr>

          <tr onmouseout="icml26_stop()" onmouseover="icml26_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/icml26.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning</papertitle>
              <br>
              Chengzu Li*, <strong>Zanyi Wang*</strong>, … Serge Belongie, Anna Korhonen
              <br>
              <em>Submitted to ICML</em>, 2026
              <br>
              <p>Exploring how visual context enhances video reasoning capabilities.</p>
            </td>
          </tr>

           <tr onmouseout="cvpr26_stop()" onmouseover="cvpr26_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/cvpr26.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Unlocking the Potential of Grounding DINO in Videos</papertitle>
              <br>
              <strong>Zanyi Wang</strong>, Fan Li, Dengyang Jiang, et al.
              <br>
              <em>Submitted to CVPR</em>, 2026
              <br>
              <p>Parameter-Efficient Adaptation for Enhanced Spatial-Temporal Localization.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>'s website.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>
</html>
